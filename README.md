<img src="MubayinApp/assets/images/logo2.png" alt="Mubayin Logo" width="350"/>


#  Mubayin | مُبيِّــــن  
## **Introduction 🌟** 
**Mubayin** is an AI-powered application designed to bridge the communication gap for the deaf-mute 
community in line with Saudi Arabia’s Vision 2030. The system uses deep learning algorithms to 
translate Arabic and American Sign Language (ArSL and ASL) into real-time written text during video 
calls. It also converts spoken voice into text and detects environmental sounds, alerting users to potential 
danger. Mubayin enhances user safety, awareness, and promotes digital accessibility and inclusion💜.

## **Technology Stack 🌟** 
- **Programming Language (Backend):** Python 🐍
- **Programming Language (Frontend):** Dart 🎨
- **Framework:** Flutter 📱
- **AI Framework:** TensorFlow ⚙️
- **Gesture Tracking:** MediaPipe ✋
- **Cloud Services:** Google Cloud ☁️
- **Database:** NoSQL 🗄️
- **Real-time Database:** Firebase 🔥
- **Tools:** Visual Studio Code, GitHub, Jira 🛠️
  
## **Launching Instructions 🌟** 

• Open the Mubayin repository on GitHub.

• Click the Code button and download the .zip file.
• Extract the .zip file.

• Open the project in Visual Studio Code.

• Go to File > Open and locate the extracted project folder.

• Use an Android Emulator or connect a real Android device.

• Run Mubayin application.

<br>

And there you go! Mubayin should now be up and running on your local machine. Enjoy exploring 💜🌟 ! <br> 

